---
title: "Alcohol and study"
author: "Pereira y Centocchi"
date: "2024-08-24"
output: pdf_document
---



```{r setup, include=FALSE}
# Configuraciones iniciales

knitr::opts_chunk$set(echo = TRUE)
library(rpart)
library(dplyr)
```


## Ejercicio 1




# Ejercicio 2

## Carga inicial de datos



```{r}
data_original <- read.csv("C:/Users/fpereira/Downloads/smoking_driking_dataset_Ver01.csv")
#data_original <- read.csv("C:/Users/matia/Downloads/smoking_driking_dataset_Ver01.csv")

set.seed(123) # Fijar semilla para reproducibilidad
data <- sample_n(data_original, 50000)


```


```{r}
# Mostrar las primeras filas del conjunto de datos
head(data)
```


## Recodificación de Columnas Numéricas a Categóricas
Nuestros datos tenian muchas variables Categóricas expresadas como números, por lo que se procedió a recodificarlas como se pidío en la consigna.
```{r recode-columns, message=FALSE, warning=FALSE}
library(dplyr)

# Recodificar la columna hear_right
data <- data %>%
  mutate(hear_right = recode(hear_right,
                             `1` = "Normal",
                             `2` = "Abnormal"))

# Recodificar la columna hear_left
data <- data %>%
  mutate(hear_left = recode(hear_left,
                            `1` = "Normal",
                            `2` = "Abnormal"))

# Recodificar la columna SMK_stat_type_cd
data <- data %>%
  mutate(SMK_stat_type_cd = recode(SMK_stat_type_cd,
                                   `1` = "No Fumador",
                                   `2` = "Ex Fumador",
                                   `3` = "Fumador Actual"))
# Recodificar la columna DRK_YN
data <- data %>%
  mutate(DRK_YN = recode(DRK_YN,
                            `1` = "Y",
                            `2` = "N"))
# Recodificar la columna urine_protein
data <- data %>%
  mutate(urine_protein = recode(urine_protein,
                                `1` = "-",
                                `2` = "+/-",
                                `3` = "+1",
                                `4` = "+2",
                                `5` = "+3",
                                `6` = "+4"))

# Mostrar las primeras filas del dataset recodificado
head(data)



```

```{r}
# Resumen estadístico de los datos
summary(data)
```





## Graficar la Distribución de Variables Numéricas y No Numéricas
Para explorar la distribución de las variables numéricas y no numéricas, se graficarán histogramas y gráficos de barras respectivamente.
```{r distribution-plot-all, message=FALSE, warning=FALSE}
library(ggplot2)

# Seleccionar las columnas numéricas y no numéricas
numeric_cols <- data[sapply(data, is.numeric)]
non_numeric_cols <- data[sapply(data, Negate(is.numeric))]

# Graficar la distribución de cada columna numérica
numeric_plots <- lapply(names(numeric_cols), function(col) {
  ggplot(data, aes_string(x = col)) +
    geom_histogram(fill = "skyblue", color = "black", bins = 50) +
    labs(title = paste("Distribución de", col), x = col, y = "Frecuencia") +
    theme_minimal()
})

# Graficar la distribución de cada columna no numérica
non_numeric_plots <- lapply(names(non_numeric_cols), function(col) {
  ggplot(data, aes_string(x = col)) +
    geom_bar(fill = "skyblue", color = "black") +
    labs(title = paste("Distribución de", col), x = col, y = "Frecuencia") +
    theme_minimal()
})

# Combinar todas las gráficas en una lista
plot_list <- c(numeric_plots, non_numeric_plots)

# Mostrar las gráficas
plot_list

```

Pudimos observar que la variable objetivo `DRK_YN`, estaba balanceada, lo cual es bueno para el modelo. Tambien la distribucion de las variables numericas no presentaba valores atipicos, su distribucion en general era normal con pocos ouliers.
Algunas clases estaba desbalanceadas, como por ejemplo la variable `hear_right` y `hear_left`.

## Graficar la Matriz de Correlación
Para continuear con la exploracion de los datos, realizamos un analisis de correlacion entre las variables numericas.
```{r correlation-matrix-groups, message=FALSE, warning=FALSE}
library(ggcorrplot)
# Dividir las columnas en grupos de 5 (puedes ajustar el tamaño del grupo)
group_size <- 9
col_groups <- split(names(numeric_cols), ceiling(seq_along(names(numeric_cols))/group_size))

# Graficar la matriz de correlación para cada grupo
for (cols in col_groups) {
  corr_matrix_group <- cor(numeric_cols[cols], use = "complete.obs")
  
  print(ggcorrplot(corr_matrix_group, 
                   method = "circle", 
                   type = "lower", 
                   lab = TRUE, 
                   lab_size = 3, 
                   colors = c("red", "white", "blue"), 
                   title = paste("Matriz de Correlación - Grupo:", paste(cols, collapse = ", ")), 
                   ggtheme = theme_minimal()))
}
```



```{r correlation-matrix-filtered, message=FALSE, warning=FALSE}
library(ggcorrplot)

# Calcular la matriz de correlación
corr_matrix <- cor(numeric_cols, use = "complete.obs")

# Filtrar correlaciones significativas (mayores en valor absoluto a 0.5)
corr_matrix_filtered <- corr_matrix
corr_matrix_filtered[abs(corr_matrix_filtered) < 0.5 ] <- NA

# Graficar la matriz de correlación filtrada
ggcorrplot(corr_matrix_filtered, 
           method = "circle", 
           type = "lower", 
           lab = TRUE,
           lab_size = 3, 
           colors = c("red", "white", "blue"), 
           title = "Matriz de Correlación Filtrada", 
           ggtheme = theme_minimal())

```

Pudimos observar que no habia correlaciones fuertes entre las variables numericas, lo cual es bueno para el modelo, ya que no hay multicolinealidad entre las variables. A exccepcion de variables que estan relacionadas por naturaleza, como por ejemplo `hear_right` y `hear_left`.

## Correlación con la Columna `DRK_YN`

## Cálculo de Correlación y Reversión de la Conversión
El siguiente paso fue analizar la correlacion con la variale a predecir, `DRK_YN`, para ello se grafico la correlacion de cada variable numerica con `DRK_YN`. para esto  recreamos la variable `DRK_YN` a un binario 1 y 0 para caluclar asi su correlacion con las variables numericas.
```{r correlation-specific-column-plot-revert, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)

# Guardar el estado original de DRK_YN
original_DRK_YN <- data$DRK_YN

# Verificar si DRK_YN es numérica; si no, convertirla
if (!is.numeric(data$DRK_YN)) {
  data$DRK_YN <- as.numeric(as.factor(data$DRK_YN))
}

# Seleccionar solo columnas numéricas
numeric_cols <- data[sapply(data, is.numeric)]

# Calcular las correlaciones de DRK_YN con todas las demás columnas
correlations <- cor(numeric_cols, use = "complete.obs")["DRK_YN", ]

# Ordenar las correlaciones en orden decreciente (opcional)
correlations <- sort(correlations, decreasing = TRUE)

# Convertir las correlaciones en un data frame para graficar
correlation_df <- data.frame(
  variable = names(correlations),
  correlation = correlations
)

# Graficar las correlaciones
ggplot(correlation_df, aes(x = reorder(variable, correlation), y = correlation)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  coord_flip() +
  labs(title = "Correlación de Variables con DRK_YN", x = "Variables", y = "Correlación") +
  theme_minimal()

# Mostrar las correlaciones
print(correlations)

# Revertir DRK_YN a su estado original
data$DRK_YN <- original_DRK_YN

```

Ninguna variable presento una correlacion mayor a un 0.4 con la variable objetivo `DRK_YN`, aun asi esperamos que el modelo pueda predecir correctamente la variable objetivo ya que todas tienen algo de correlacion y combinandolas podrian revelar relaciones a DRK_YN`.

```{r}
# Mostrar las primeras filas del conjunto de datos
head(data)
```

## División del Conjunto de Datos en Entrenamiento, Validación y Testeo

``` {r data-split, message=FALSE, warning=FALSE}
# Fijar la semilla para asegurar la replicabilidad
set.seed(123)

# Número total de observaciones
n <- nrow(data)

# Crear un vector de índices mezclados
indices <- sample(1:n)

# Definir los tamaños para cada partición
train_size <- floor(0.70 * n)
validation_size <- floor(0.15 * n)
test_size <- n - train_size - validation_size

# Crear los índices para cada partición
train_indices <- indices[1:train_size]
validation_indices <- indices[(train_size + 1):(train_size + validation_size)]
test_indices <- indices[(train_size + validation_size + 1):n]

# Dividir el conjunto de datos en las tres particiones
train_data <- data[train_indices, ]
validation_data <- data[validation_indices, ]
test_data <- data[test_indices, ]

# Mostrar el tamaño de cada conjunto
cat("Tamaño del conjunto de entrenamiento:", nrow(train_data), "\n")
cat("Tamaño del conjunto de validación:", nrow(validation_data), "\n")
cat("Tamaño del conjunto de testeo:", nrow(test_data), "\n")
``` 
``` {r entrenamiento default  message=FALSE, warning=FALSE}
#install.packages("rpart.plot")
library(rpart.plot)
arbol_modelo <- rpart(DRK_YN ~ ., data = train_data, method = "class")

# Visualizar el árbol
rpart.plot(arbol_modelo)
``` 


```{r}
# Obtener la importancia de las variables directamente del modelo
importancia <- arbol_modelo$variable.importance

# Ordenar la importancia de mayor a menor
importancia <- sort(importancia, decreasing = TRUE)

# Mostrar la importancia
print(importancia)

# Visualizar la importancia de las variables
barplot(importancia, las = 2, col = "blue", main = "Importancia de las Variables")

```



``` {r error-metrics, message=FALSE, warning=FALSE}
# Instalar paquetes necesarios
#install.packages("caret")
#install.packages("e1071")
#install.packages("pROC")

# Cargar librerías
library(caret)
library(pROC)

# Realizar predicciones en el conjunto de validación
predicciones <- predict(arbol_modelo, newdata = validation_data, type = "class")

# Convertir validation_data$DRK_YN a factor y eliminar niveles no usados
validation_data$DRK_YN <- as.factor(validation_data$DRK_YN)
validation_data$DRK_YN <- droplevels(validation_data$DRK_YN)

# Convertir predicciones a factor con los mismos niveles que validation_data$DRK_YN
niveles <- levels(validation_data$DRK_YN)
predicciones <- factor(predicciones, levels = niveles)

# Crear la matriz de confusión
confusion_matrix <- confusionMatrix(predicciones, validation_data$DRK_YN)
print(confusion_matrix)

# Obtener la precisión
accuracy <- confusion_matrix$overall["Accuracy"]
print(accuracy)

# Calcular la precisión y el recall
precision <- confusion_matrix$byClass["Precision"]
recall <- confusion_matrix$byClass["Recall"]
print(precision)
print(recall)

# Calcular el F1-score
f1_score <- 2 * (precision * recall) / (precision + recall)
print("f1_score")
print(f1_score)

# Calcular el AUC-ROC
roc_curve <- roc(as.numeric(validation_data$DRK_YN), as.numeric(predicciones))
auc_roc <- auc(roc_curve)

# Mostrar el AUC-ROC
print(auc_roc)


```

# Ejercicio 5

En una primera instancia exploramos manualmente con distintas combinacion paraa darnos una iddea de en que rango se podian encontrar los hiperparametros que buscabamos.

```{r}
arbol_modelo <- rpart(DRK_YN ~ ., data = train_data, method = "class",
                      cp = 0,           # Parámetro de complejidad
                      xval = 0,
                      minsplit = 300,       # Mínimo número de observaciones en un nodo antes de dividir
                      minbucket = 100,     # Mínimo número de observaciones en un nodo terminal
                      maxdepth = 9)        # Profundidad máxima del árbol

# Calcular el AUC-ROC
predicciones <- predict(arbol_modelo, newdata = validation_data, type = "class")
roc_curve <- roc(as.numeric(validation_data$DRK_YN), as.numeric(predicciones))
auc_roc <- auc(roc_curve)

# Mostrar el AUC-ROC
print(auc_roc)

```

## Búsqueda de Hiperparámetros Óptimos
Para encontrar los hiperparámetros óptimos, se realizará una búsqueda exhaustiva de todas las combinaciones posibles de los hiperparámetros `minsplit`, `minbucket` y `maxdepth`. Se entrenará un modelo para cada combinación y se calculará el AUC-ROC en el conjunto de validación. Finalmente, se seleccionará la combinación que maximice el AUC-ROC.


```{r}
# Cargar las librerías necesarias
library(rpart)
library(pROC)

# Inicializar un data frame para guardar los resultados
resultados <- data.frame(minsplit = integer(),
                         minbucket = integer(),
                         maxdepth = integer(),
                         auc_roc = numeric(),
                         stringsAsFactors = FALSE)

# Definir los rangos de los hiperparámetros
minsplit_values <- seq(50, 500, by = 25)
minbucket_values <- seq(50, 150, by = 10)
maxdepth_values <- seq(1, 15, by = 1)

# Triple for para recorrer todas las combinaciones de hiperparámetros
for (minsplit in minsplit_values) {
  for (minbucket in minbucket_values) {
    for (maxdepth in maxdepth_values) {
      
      # Entrenar el modelo con la combinación actual de hiperparámetros
      arbol_modelo <- rpart(DRK_YN ~ ., data = train_data, method = "class",
                            cp = 0,           # Parámetro de complejidad
                            xval = 0,
                            minsplit = minsplit,       # Mínimo número de observaciones en un nodo antes de dividir
                            minbucket = minbucket,     # Mínimo número de observaciones en un nodo terminal
                            maxdepth = maxdepth)        # Profundidad máxima del árbol
      
      # Calcular el AUC-ROC
      predicciones <- predict(arbol_modelo, newdata = validation_data, type = "class")
      roc_curve <- roc(as.numeric(validation_data$DRK_YN), as.numeric(predicciones), quiet = TRUE)
      auc_roc <- auc(roc_curve)
      
      # Guardar los resultados en el data frame
      resultados <- rbind(resultados, data.frame(minsplit = minsplit, 
                                                 minbucket = minbucket, 
                                                 maxdepth = maxdepth, 
                                                 auc_roc = auc_roc))
    }
  }
}

# Mostrar los resultados
print(resultados)

```

```{r}
# Encontrar el índice del máximo AUC-ROC
max_index <- which.max(resultados$auc_roc)

# Extraer los valores correspondientes a ese índice
max_auc_roc <- resultados$auc_roc[max_index]
best_params <- resultados[max_index, ]

# Imprimir el AUC-ROC máximo y los hiperparámetros correspondientes
cat("El máximo AUC-ROC es:", max_auc_roc, "\n")
cat("Logrado con minsplit =", best_params$minsplit, 
    ", minbucket =", best_params$minbucket, 
    ", maxdepth =", best_params$maxdepth, "\n")
```

```{r}


# Encontrar el mejor AUC-ROC para cada valor de minsplit
best_by_minsplit <- aggregate(auc_roc ~ minsplit, data = resultados, max)

# Gráfico para minsplit
ggplot(best_by_minsplit, aes(x = minsplit, y = auc_roc)) +
  geom_line() +
  geom_point() +
  labs(title = "Mejor AUC-ROC por minsplit",
       x = "minsplit",
       y = "AUC-ROC") +
  theme_minimal()

# Encontrar el mejor AUC-ROC para cada valor de minbucket
best_by_minbucket <- aggregate(auc_roc ~ minbucket, data = resultados, max)

# Gráfico para minbucket
ggplot(best_by_minbucket, aes(x = minbucket, y = auc_roc)) +
  geom_line() +
  geom_point() +
  labs(title = "Mejor AUC-ROC por minbucket",
       x = "minbucket",
       y = "AUC-ROC") +
  theme_minimal()

# Encontrar el mejor AUC-ROC para cada valor de maxdepth
best_by_maxdepth <- aggregate(auc_roc ~ maxdepth, data = resultados, max)

# Gráfico para maxdepth
ggplot(best_by_maxdepth, aes(x = maxdepth, y = auc_roc)) +
  geom_line() +
  geom_point() +
  labs(title = "Mejor AUC-ROC por maxdepth",
       x = "maxdepth",
       y = "AUC-ROC") +
  theme_minimal()

```
```{r}
#Esto seria el punto 6 pero no veo mucha diferencia (?)
arbol_modelo2 <- rpart(DRK_YN ~ ., data = train_data, method = "class",
                            cp = 0,           # Parámetro de complejidad
                            xval = 0,
                            minsplit = 50,       # Mínimo número de observaciones en un nodo antes de dividir
                            minbucket = 100,     # Mínimo número de observaciones en un nodo terminal
                            maxdepth = 11)  

# Visualizar el árbol
rpart.plot(arbol_modelo2)
```
```{r}
# Obtener la importancia de las variables directamente del modelo
importancia <- arbol_modelo$variable.importance

# Ordenar la importancia de mayor a menor
importancia <- sort(importancia, decreasing = TRUE)

# Mostrar la importancia
print(importancia)


importancia2 <- arbol_modelo2$variable.importance

# Ordenar la importancia de mayor a menor
importancia2 <- sort(importancia2, decreasing = TRUE)

# Mostrar la importancia
print(importancia2)

# Visualizar la importancia de las variables
barplot(importancia, las = 2, col = "blue", main = "Importancia de las Variables")

# Visualizar la importancia de las variables
barplot(importancia2, las = 2, col = "blue", main = "Importancia de las Variables")
```






```{r}
# Función para agregar NA a un porcentaje de datos
introduce_nas <- function(data, percentage) {
  set.seed(123)  # Fijar semilla para reproducibilidad
  data_with_nas <- data
  for (col in names(data_with_nas)) {
    if (!is.numeric(data_with_nas[[col]])) next  # Saltar variables no numéricas
    na_indices <- sample(seq_len(nrow(data_with_nas)), size = floor(percentage * nrow(data_with_nas)))
    data_with_nas[na_indices, col] <- NA
  }
  return(data_with_nas)
}

# Crear los conjuntos de datos con valores faltantes
train_data_20 <- introduce_nas(train_data, 0.20)
train_data_50 <- introduce_nas(train_data, 0.50)
train_data_75 <- introduce_nas(train_data, 0.75)
```

```{r}
library(rpart)
library(pROC)

# Función para entrenar el modelo y calcular el AUC-ROC
entrenar_arbol_y_calcular_auc <- function(train_data, valid_data, maxdepth, minsplit, minbucket) {
  arbol_modelo <- rpart(DRK_YN ~ ., data = train_data, method = "class",
                        control = rpart.control(maxdepth = maxdepth, minsplit = minsplit, minbucket = minbucket, cp = 0, xval = 0))
  
  # Predecir probabilidades en el conjunto de validación
  predicciones <- predict(arbol_modelo, newdata = valid_data, type = "class")
  
  # Calcular ROC-AUC
  roc_curve <- roc(as.numeric(valid_data$DRK_YN), as.numeric(predicciones))
  auc_roc <- auc(roc_curve)
  
  return(auc_roc)
}

# Entrenar y calcular AUC para cada conjunto de datos con diferentes valores faltantes
auc_20 <- entrenar_arbol_y_calcular_auc(train_data_20, validation_data, maxdepth = 5, minsplit = 20, minbucket = 7)
auc_50 <- entrenar_arbol_y_calcular_auc(train_data_50, validation_data, maxdepth = 5, minsplit = 20, minbucket = 7)
auc_75 <- entrenar_arbol_y_calcular_auc(train_data_75, validation_data, maxdepth = 5, minsplit = 20, minbucket = 7)

# Mostrar los resultados de AUC-ROC
cat("AUC-ROC para 20% de NA:", auc_20, "\n")
cat("AUC-ROC para 50% de NA:", auc_50, "\n")
cat("AUC-ROC para 75% de NA:", auc_75, "\n")
```

```{r}
# Inicializar un data frame para guardar los resultados_2
resultados_2 <- data.frame(minsplit = integer(),
                         minbucket = integer(),
                         maxdepth = integer(),
                         auc_roc_20 = numeric(),
                         auc_roc_50 = numeric(),
                         auc_roc_75 = numeric(),
                         stringsAsFactors = FALSE)

# Definir los rangos de los hiperparámetros
minsplit_values <- seq(50, 500, by = 25)
minbucket_values <- seq(50, 150, by = 10)
maxdepth_values <- seq(1, 15, by = 1)

# Triple for para recorrer todas las combinaciones de hiperparámetros
for (minsplit in minsplit_values) {
  for (minbucket in minbucket_values) {
    for (maxdepth in maxdepth_values) {
      
      # Entrenar el modelo con la combinación actual de hiperparámetros para 20% NA
      arbol_modelo_20 <- rpart(DRK_YN ~ ., data = train_data_20, method = "class",
                               control = rpart.control(maxdepth = maxdepth, minsplit = minsplit, minbucket = minbucket, cp = 0, xval = 0))
      predicciones_20 <- predict(arbol_modelo_20, newdata = validation_data, type = "class")
      roc_curve_20 <- roc(as.numeric(validation_data$DRK_YN), as.numeric(predicciones_20), quiet = TRUE)
      auc_roc_20 <- auc(roc_curve_20)
      
      # Entrenar el modelo con la combinación actual de hiperparámetros para 50% NA
      arbol_modelo_50 <- rpart(DRK_YN ~ ., data = train_data_50, method = "class",
                               control = rpart.control(maxdepth = maxdepth, minsplit = minsplit, minbucket = minbucket, cp = 0, xval = 0))
      predicciones_50 <- predict(arbol_modelo_50, newdata = validation_data, type = "class")
      roc_curve_50 <- roc(as.numeric(validation_data$DRK_YN), as.numeric(predicciones_50), quiet = TRUE)
      auc_roc_50 <- auc(roc_curve_50)
      
      # Entrenar el modelo con la combinación actual de hiperparámetros para 75% NA
      arbol_modelo_75 <- rpart(DRK_YN ~ ., data = train_data_75, method = "class",
                               control = rpart.control(maxdepth = maxdepth, minsplit = minsplit, minbucket = minbucket, cp = 0, xval = 0))
      predicciones_75 <- predict(arbol_modelo_75, newdata = validation_data, type = "class")
      roc_curve_75 <- roc(as.numeric(validation_data$DRK_YN), as.numeric(predicciones_75), quiet = TRUE)
      auc_roc_75 <- auc(roc_curve_75)
      
      # Guardar los resultados_2 en el data frame
      resultados_2 <- rbind(resultados_2, data.frame(minsplit = minsplit, 
                                                 minbucket = minbucket, 
                                                 maxdepth = maxdepth, 
                                                 auc_roc_20 = auc_roc_20,
                                                 auc_roc_50 = auc_roc_50,
                                                 auc_roc_75 = auc_roc_75))
    }
  }
}

# Mostrar los resultados_2
print(resultados_2)
```

```{r}
# Encontrar el índice del máximo AUC-ROC para cada nivel de NA
max_index_20 <- which.max(resultados_2$auc_roc_20)
max_index_50 <- which.max(resultados_2$auc_roc_50)
max_index_75 <- which.max(resultados_2$auc_roc_75)

# Extraer los valores correspondientes a esos índices
max_auc_roc_20 <- resultados_2$auc_roc_20[max_index_20]
best_params_20 <- resultados_2[max_index_20, ]

max_auc_roc_50 <- resultados_2$auc_roc_50[max_index_50]
best_params_50 <- resultados_2[max_index_50, ]

max_auc_roc_75 <- resultados_2$auc_roc_75[max_index_75]
best_params_75 <- resultados_2[max_index_75, ]

# Imprimir el AUC-ROC máximo y los hiperparámetros correspondientes para cada nivel de NA
cat("El máximo AUC-ROC para 20% de NA es:", max_auc_roc_20, "\n")
cat("Logrado con minsplit =", best_params_20$minsplit, 
    ", minbucket =", best_params_20$minbucket, 
    ", maxdepth =", best_params_20$maxdepth, "\n")

cat("El máximo AUC-ROC para 50% de NA es:", max_auc_roc_50, "\n")
cat("Logrado con minsplit =", best_params_50$minsplit, 
    ", minbucket =", best_params_50$minbucket, 
    ", maxdepth =", best_params_50$maxdepth, "\n")

cat("El máximo AUC-ROC para 75% de NA es:", max_auc_roc_75, "\n")
cat("Logrado con minsplit =", best_params_75$minsplit, 
    ", minbucket =", best_params_75$minbucket, 
    ", maxdepth =", best_params_75$maxdepth, "\n")

```

```{r}
# Gráfico para maxdepth (Para 20% NA)
best_by_maxdepth_20 <- aggregate(auc_roc_20 ~ maxdepth, data = resultados_2, max)
ggplot(best_by_maxdepth_20, aes(x = maxdepth, y = auc_roc_20)) +
  geom_line() +
  geom_point() +
  labs(title = "Mejor AUC-ROC por maxdepth (20% NA)",
       x = "maxdepth",
       y = "AUC-ROC") +
  theme_minimal()

# Gráfico para maxdepth (Para 50% NA)
best_by_maxdepth_50 <- aggregate(auc_roc_50 ~ maxdepth, data = resultados_2, max)
ggplot(best_by_maxdepth_50, aes(x = maxdepth, y = auc_roc_50)) +
  geom_line() +
  geom_point() +
  labs(title = "Mejor AUC-ROC por maxdepth (50% NA)",
       x = "maxdepth",
       y = "AUC-ROC") +
  theme_minimal()

# Gráfico para maxdepth (Para 50% NA)
best_by_maxdepth_75 <- aggregate(auc_roc_75 ~ maxdepth, data = resultados_2, max)
ggplot(best_by_maxdepth_75, aes(x = maxdepth, y = auc_roc_75)) +
  geom_line() +
  geom_point() +
  labs(title = "Mejor AUC-ROC por maxdepth (75% NA)",
       x = "maxdepth",
       y = "AUC-ROC") +
  theme_minimal()

```

```{r}
best_by_minbucket_20 <- aggregate(auc_roc_20 ~ minbucket, data = resultados_2, max)
ggplot(best_by_minbucket_20, aes(x = minbucket, y = auc_roc_20)) +
  geom_line() +
  geom_point() +
  labs(title = "Mejor AUC-ROC por minbucket (20% NA)",
       x = "minbucket",
       y = "AUC-ROC") +
  theme_minimal()

# Gráfico para minbucket (Para 50% NA)
best_by_minbucket_50 <- aggregate(auc_roc_50 ~ minbucket, data = resultados_2, max)
ggplot(best_by_minbucket_50, aes(x = minbucket, y = auc_roc_50)) +
  geom_line() +
  geom_point() +
  labs(title = "Mejor AUC-ROC por minbucket (50% NA)",
       x = "minbucket",
       y = "AUC-ROC") +
  theme_minimal()

# Gráfico para minbucket (Para 50% NA)
best_by_minbucket_75 <- aggregate(auc_roc_75 ~ minbucket, data = resultados_2, max)
ggplot(best_by_minbucket_75, aes(x = minbucket, y = auc_roc_75)) +
  geom_line() +
  geom_point() +
  labs(title = "Mejor AUC-ROC por minbucket (75% NA)",
       x = "minbucket",
       y = "AUC-ROC") +
  theme_minimal()
```

```{r}

```


